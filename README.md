# Jarv1s: Your Personal AI Co-pilot

[![Status](https://img.shields.io/badge/status-Functional%20Prototype-green.svg)](https://github.com/danrodev/Jarv1s)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](/LICENSE)

## Unleash Your Potential with a Truly Personal AI

**Jarv1s** isn't just another assistant; it's a powerful, privacy-focused AI co-pilot designed to run entirely on your own machine. Built for ultimate control and customization, Jarv1s integrates seamlessly into your digital life, helping you organize, research, and create like never before. **Forget the cloud‚Äîyour data, your rules, your AI.**

## Project Status: Functional Prototype

El proyecto ha alcanzado con √©xito su primer gran hito: un **prototipo full-stack funcional**. El sistema actual permite mantener una conversaci√≥n de voz fluida y coherente a trav√©s de una interfaz web, validando la arquitectura central y el stack tecnol√≥gico. La base est√° construida y es robusta.

## Core Features (Vision)

Esta es la visi√≥n a largo plazo para las capacidades de Jarv1s:

*   üó£Ô∏è **Fluid Voice Conversation:** Interact naturally with Jarv1s using your voice.
*   üîí **100% Local & Private:** Your conversations and data never leave your computer.
*   üöÄ **Productivity Maximizer:** Manage your calendar, organize notes, and streamline daily tasks.
*   üß† **Intelligent Research Assistant:** Summarize complex PDF documents and scour the web for information.
*   üõ†Ô∏è **Hyper-Modular Architecture:** Built on Google's Agent Development Kit for straightforward extensibility.

## Architecture of the Functional Prototype

El sistema actual opera con una arquitectura desacoplada Cliente-Servidor. El Frontend (React) captura el audio y renderiza la respuesta, mientras que el Backend (Python/FastAPI) realiza todo el procesamiento de IA.

```mermaid
graph TD
    subgraph Frontend (React @ localhost:5173)
        A[UI Orb: Push-to-Talk] -->|1. Records Audio (WEBM)| B(Sends via POST Request);
        B --> C{Backend API};
        D[Receives JSON Response] --> E(Decodes Base64 & Plays Audio);
    end

    subgraph Backend (Python @ localhost:8000)
        C --> F[Endpoint /interact];
        F --> G[STT Service];
        G --Converts WEBM to WAV w/ FFmpeg--> H((Whisper Model));
        H -->|Transcribed Text| I[LLM Service];
        I -->|Prompt w/ History| J{LM Studio};
        J -->|LLM Response| I;
        I -->|Response Text| K[TTS Service];
        K --Generates PCM Audio--> L((Piper TTS Model));
        L --Packages into valid WAV--> K;
        K -->|JSON with Base64 Audio| F;
        F --> D;
    end

    style A fill:#87CEEB,stroke:#333,stroke-width:2px
    style E fill:#87CEEB,stroke:#333,stroke-width:2px
    style F fill:#90EE90,stroke:#333,stroke-width:2px
    style J fill:#FFD700,stroke:#333,stroke-width:2px
```

## The Tech Stack Powering Jarv1s

El stack tecnol√≥gico ha sido cuidadosamente seleccionado para cumplir con los objetivos de rendimiento y privacidad.

#### Backend
*   **Lenguaje:** Python 3.10+
*   **Framework de API:** FastAPI con Uvicorn
*   **Speech-to-Text (STT):** OpenAI Whisper (Modelo `small` ejecut√°ndose en CPU)
*   **Text-to-Speech (TTS):** Piper TTS (Voz de alta calidad y baja latencia)
*   **Conector Universal de LLM:** LiteLLM
*   **Manipulaci√≥n de Audio:** FFmpeg (invocado directamente para una conversi√≥n robusta)

#### Frontend
*   **Framework:** React (con Vite y TypeScript)
*   **Animaci√≥n:** Framer Motion
*   **Cliente HTTP:** Axios
*   **Grabaci√≥n de Audio:** API nativa `MediaRecorder` del navegador.

#### Inferencia de IA
*   **Servidor LLM Local:** LM Studio

---

## Getting Started: ¬°Poniendo en Marcha el Prototipo!

Sigue estos pasos para ejecutar el ecosistema completo de Jarv1s en tu m√°quina.

### 1. Prerrequisitos
Aseg√∫rate de tener instalado:
-   **Python 3.10+** y `pip`.
-   **Node.js y `npm`**.
-   **FFmpeg:** `sudo apt install ffmpeg` (Linux) o `brew install ffmpeg` (macOS).
-   **LM Studio:** Descargado, instalado y con un modelo de lenguaje (ej. `Phi-3-mini-4k-instruct-q4.gguf`) listo para usar.

### 2. Configuraci√≥n del Backend

```bash
# 1. Navega a la carpeta del backend
cd local-agent-suite # O el nombre que le hayas dado

# 2. Crea y activa un entorno virtual
python -m venv .venv
source .venv/bin/activate

# 3. Instala las dependencias de Python
pip install -r requirements.txt # (Aseg√∫rate de crear este archivo con 'pip freeze')
# O inst√°lalas manualmente: pip install fastapi uvicorn python-multipart python-dotenv openai-whisper torch piper-tts pydub litellm

# 4. Configura tus variables de entorno
cp .env.example .env

# 5. Inicia el servidor de LM Studio y aseg√∫rate de que est√© escuchando.

# 6. Lanza el backend de Jarv1s
uvicorn src.main:app --reload
```

### 3. Configuraci√≥n del Frontend

Abre una **nueva terminal**.

```bash
# 1. Navega a la carpeta del frontend
cd jarv1s-frontend # O el nombre que le hayas dado

# 2. Instala las dependencias de Node.js
npm install

# 3. Lanza el servidor de desarrollo
npm run dev
```

### 4. ¬°A Conversar!

Abre tu navegador y ve a la direcci√≥n que te proporcion√≥ Vite (normalmente `http://localhost:5173`). ¬°Mant√©n presionada la barra espaciadora y comienza tu primera conversaci√≥n con Jarv1s!

---

## Hoja de Ruta (Roadmap)

Este prototipo funcional es solo el comienzo. Los pr√≥ximos pasos se centrar√°n en construir sobre esta s√≥lida base:
-   [ ] **Integrar Google Agent Development Kit (ADK):** Reemplazar la l√≥gica simple del LLM por un verdadero framework de agente para una orquestaci√≥n avanzada de herramientas.
-   [ ] **Desarrollar Herramientas (Tools):** Implementar las habilidades clave del MVP:
    -   [ ] B√∫squeda en la web.
    -   [ ] Lector y resumidor de documentos PDF.
-   [ ] **Optimizar el STT:** Investigar la implementaci√≥n de `whisper.cpp` para una transcripci√≥n a√∫n m√°s r√°pida en CPU.
-   [ ] **Mejorar la UX:** Implementar la visualizaci√≥n de los "pensamientos" o herramientas que Jarv1s est√° usando en tiempo real en la interfaz.

---

### A Note on the Project's Purpose

**Jarv1s** is an ambitious open-source project born from a passion for learning. Its primary goal is to serve as a practical testbed to explore, understand, and deepen knowledge in the fascinating fields of **agentic AI systems**, **multi-agent construction**, and **Natural Language Processing (NLP)**. Every feature and challenge is a stepping stone on this educational journey.